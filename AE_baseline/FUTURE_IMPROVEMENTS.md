# í–¥í›„ ê°œì„  ì‚¬í•­ (Spatial ì •ë³´ ì¶”ê°€)

## í˜„ì¬ ìƒíƒœ (v1.0)
- âœ… 2D ì§ì ‘ ë¡œë“œ ë°©ì‹ êµ¬í˜„
- âœ… 422ë°° ë¹ ë¥¸ ì†ë„
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- âŒ Spatial context ì—†ìŒ

---

## ğŸ¯ í–¥í›„ ê°œì„  ë°©í–¥

### Phase 1: Multi-Slice Input (2.5D) 
**ëª©í‘œ**: ì¸ì ‘ ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ í™œìš©

#### êµ¬í˜„ ë°©ë²•:
```python
# í˜„ì¬ (1-slice)
input: (1, H, W)  # ë‹¨ì¼ ìŠ¬ë¼ì´ìŠ¤

# ê°œì„  (3-slice)
input: (3, H, W)  # [ì´ì „, í˜„ì¬, ë‹¤ìŒ] ìŠ¬ë¼ì´ìŠ¤
```

#### ì½”ë“œ ìˆ˜ì • ìœ„ì¹˜:
```
dataload.py:
  - __init__(): use_multi_slice íŒŒë¼ë¯¸í„° ì¶”ê°€
  - __getitem__(): ì¸ì ‘ ìŠ¬ë¼ì´ìŠ¤ ë¡œë“œ ë¡œì§ ì¶”ê°€
  - _load_adjacent_slice(): í—¬í¼ í•¨ìˆ˜ êµ¬í˜„

networks/ae.py:
  - in_planes=1 â†’ in_planes=3 (3ì±„ë„ ì…ë ¥)
```

#### ì˜ˆìƒ íš¨ê³¼:
- âœ… ì¼ë¶€ depth ì •ë³´ ë³µì›
- âœ… ê²½ê³„ ì •ë³´ ê°œì„ 
- âš ï¸ ë©”ëª¨ë¦¬ 3ë°° ì¦ê°€
- âš ï¸ ì•½ê°„ì˜ ì†ë„ ì €í•˜

---

### Phase 2: Positional Encoding
**ëª©í‘œ**: ìŠ¬ë¼ì´ìŠ¤ ìœ„ì¹˜ ì •ë³´ ì œê³µ

#### êµ¬í˜„ ë°©ë²•:
```python
# ìŠ¬ë¼ì´ìŠ¤ ìœ„ì¹˜ë¥¼ ëª¨ë¸ì— ì œê³µ
slice_position = slice_idx / total_depth  # 0~1 ì •ê·œí™”

# ì˜µì…˜ 1: ì¶”ê°€ ì…ë ¥ ì±„ë„
pos_channel = np.ones((H, W)) * slice_position
input = np.stack([slice_2d, pos_channel])  # (2, H, W)

# ì˜µì…˜ 2: Concatenate to latent
latent = encoder(img)
latent_with_pos = torch.cat([latent, pos_embedding], dim=1)
```

#### ì½”ë“œ ìˆ˜ì • ìœ„ì¹˜:
```
dataload.py:
  - __getitem__(): position encoding ì¶”ê°€
  
networks/ae.py:
  - forward(): positional info ì²˜ë¦¬
```

#### ì˜ˆìƒ íš¨ê³¼:
- âœ… ìŠ¬ë¼ì´ìŠ¤ ìœ„ì¹˜ ì •ë³´ í™œìš©
- âœ… ìƒ/ì¤‘/í•˜ ë¶€ìœ„ë³„ íŠ¹ì„± í•™ìŠµ ê°€ëŠ¥
- âœ… ê³„ì‚°ëŸ‰ ì¦ê°€ ê±°ì˜ ì—†ìŒ

---

### Phase 3: 3D Patch-based Approach
**ëª©í‘œ**: ì‘ì€ 3D patchë¡œ í•™ìŠµ

#### êµ¬í˜„ ë°©ë²•:
```python
# ì „ì²´ ë³¼ë¥¨ ëŒ€ì‹  ì‘ì€ 3D patch ì‚¬ìš©
patch_size = (16, 64, 64)  # (D, H, W)

# Random patch sampling
start_d = random.randint(0, depth - 16)
patch = volume[start_d:start_d+16, :, :]
```

#### ì½”ë“œ ìˆ˜ì • ìœ„ì¹˜:
```
dataload.py:
  - __getitem__(): 3D patch extraction ì¶”ê°€
  
networks/:
  - Conv2d â†’ Conv3d ë³€í™˜
  - 3D ì•„í‚¤í…ì²˜ êµ¬í˜„
```

#### ì˜ˆìƒ íš¨ê³¼:
- âœ… ì™„ì „í•œ 3D context ë³µì›
- âœ… ì‘ì€ patchë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
- âŒ ì½”ë“œ ëŒ€í­ ìˆ˜ì • í•„ìš”
- âŒ í•™ìŠµ ì‹œê°„ ì¦ê°€

---

### Phase 4: Attention Mechanism
**ëª©í‘œ**: Slice ê°„ ê´€ê³„ í•™ìŠµ

#### êµ¬í˜„ ë°©ë²•:
```python
# Transformer-based attention
# ì—¬ëŸ¬ ìŠ¬ë¼ì´ìŠ¤ë¥¼ sequenceë¡œ ì·¨ê¸‰

slice_sequence = [slice_1, slice_2, ..., slice_N]
attended_features = transformer_encoder(slice_sequence)
```

#### ì˜ˆìƒ íš¨ê³¼:
- âœ… Long-range dependency í•™ìŠµ
- âœ… Slice ê°„ ê´€ê³„ ëª¨ë¸ë§
- âŒ ëª¨ë¸ ë³µì¡ë„ ëŒ€í­ ì¦ê°€

---

## ğŸ“‹ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### ì¦‰ì‹œ ê°€ëŠ¥ (í˜„ì¬ ì½”ë“œ ê¸°ë°˜):
1. âœ… **2D Direct Load** (ì™„ë£Œ!)
2. ğŸ”œ AE/AE-U ëª¨ë¸ í•™ìŠµ (reconstruction ì½”ë“œ í™œìš©)
3. ğŸ”œ ê²°ê³¼ í‰ê°€ ë° baseline ì„¤ì •

### ë‹¨ê¸° ê°œì„  (1-2ì£¼):
4. ğŸ¯ **Multi-Slice Input (2.5D)** - ì¶”ì²œ!
   - ì½”ë“œ ìˆ˜ì • ìµœì†Œ
   - ì„±ëŠ¥ í–¥ìƒ ê¸°ëŒ€
   
5. ğŸ¯ **Positional Encoding**
   - êµ¬í˜„ ê°„ë‹¨
   - ì¶”ê°€ ì •ë³´ ì œê³µ

### ì¥ê¸° ê°œì„  (1ê°œì›”+):
6. ğŸ”® 3D Patch-based
7. ğŸ”® Attention Mechanism

---

## ğŸ’¡ í˜„ì¬ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

### ğŸ“Œ ì§€ê¸ˆ í•´ì•¼ í•  ê²ƒ:
```
1. reconstruction ì½”ë“œë¥¼ sw_capstoneìœ¼ë¡œ ë³µì‚¬
   - networks/ae.py (2D AE)
   - networks/aeu.py (2D AE-U)
   - networks/base_units/*.py
   - utils/losses.py
   - utils/*_worker.py

2. train.py, test.py êµ¬í˜„

3. í•™ìŠµ ì‹¤í–‰ ë° baseline ê²°ê³¼ í™•ë³´

4. ê²°ê³¼ ë¶„ì„ í›„ ê°œì„  ë°©í–¥ ê²°ì •
```

### ğŸ“Œ Spatial ì •ë³´ëŠ”:
- ì¼ë‹¨ 2Dë¡œ baseline ê²°ê³¼ í™•ë³´
- ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ë©´ Multi-Slice (2.5D) ì¶”ê°€
- ì½”ë“œì— TODO ì£¼ì„ìœ¼ë¡œ í™•ì¥ í¬ì¸íŠ¸ í‘œì‹œ ì™„ë£Œ

---

## ğŸ”– í™•ì¥ í¬ì¸íŠ¸ ìœ„ì¹˜

### dataload.py
```python
Line ~240: # TODO [í–¥í›„ ê°œì„ ]: Multi-slice ë¡œë“œ
Line ~250: # TODO [í–¥í›„ ê°œì„ ]: Positional encoding
Line ~273: # def _load_adjacent_slice(): í—¬í¼ í•¨ìˆ˜
```

### í–¥í›„ íŒŒë¼ë¯¸í„° ì¶”ê°€ ì˜ˆì •:
```python
CQ500Dataset(
    ...
    use_multi_slice=False,      # TODO: 2.5D êµ¬í˜„ ì‹œ
    num_adjacent_slices=1,      # TODO: ì¸ì ‘ ìŠ¬ë¼ì´ìŠ¤ ê°œìˆ˜
    add_positional_encoding=False,  # TODO: ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
    ...
)
```

ì¤€ë¹„ ì™„ë£Œ! ì´ì œ AE ëª¨ë¸ êµ¬í˜„ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?

